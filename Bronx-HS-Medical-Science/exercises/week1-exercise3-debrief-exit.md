# WEEK 1, EXERCISE 3: Debrief & Exit Ticket
## Bronx HS for Medical Science — "Data to Diagnosis"

**Exercise Type**: Debrief / Share-Out + Exit Ticket  
**Duration**: 8 minutes  
**Timing in Lesson**: 0:36–0:44 (Closing)  
**Mode**: Whole class share-out, then individual exit ticket  

---

## LEARNING OBJECTIVES

Students will:
1. Articulate what they learned from the prompt-and-verify exercise
2. Share one risk and one benefit of AI in healthcare with evidence or reasoning
3. Demonstrate understanding of medical AI and the importance of verification (via exit ticket)

---

## MATERIALS NEEDED

- [ ] Student handouts from Exercise 2 (for reference during share-out)
- [ ] **Slide 11** projected (Exit Ticket question)
- [ ] Google Classroom set up with exit ticket assignment
- [ ] Whiteboard/markers to capture key points during debrief
- [ ] Timer (visible to students)

---

## TEACHER PREPARATION (Before Class)

1. **Pre-select 2 pairs to share** (optional):
   - While circulating during Exercise 2, note 2 pairs who:
     - Had a clear prompt
     - Found something interesting when fact-checking
     - Have a good risk/benefit to share
   - Gives you a backup if volunteers are slow

2. **Set up Google Classroom exit ticket**:
   - Create an assignment titled "Week 1 Exit Ticket"
   - Copy the exact wording (see below)
   - Set it to accept short answer responses
   - Test submission from a student account

3. **Prepare to synthesize**:
   - During share-out, you'll need to draw connections between what students say and the day's key concepts
   - Have a mental list of the 3–4 main takeaways (see "Key Teaching Points" below)

---

## STEP-BY-STEP INSTRUCTIONS

### MINUTE 0:36–0:39 — Share-Out: Prompts & Verification (3 min)

**What you do:**

1. Say:

> *"Let's hear from a few pairs. I want to know:*
> 1. *What prompt did you write?*
> 2. *What's one thing you verified—or would verify—against a trusted source?"*

2. Call on **2 students (or pairs)**. For each:
   - *"What was your prompt?"*
   - *"What did the AI say?"*
   - *"What did you check? Did it match the CDC or NIH?"*

3. After each share, **affirm and connect**:
   - *"Great. So you verified the AI's answer against a trusted source. That's evidence-based practice."*
   - If they found a discrepancy: *"Excellent catch. That's exactly why we don't just trust the first answer."*
   - If they found it accurate: *"Good. But you still checked—that's the point. Verify, then act."*

4. Write key points on the board:
   - **Verification matters**
   - **Check against trusted sources (CDC, NIH, textbook)**
   - **Even 'correct' answers might be incomplete**

**What students do:**
- Listen to peers share
- Reflect on their own verification process
- Connect their experience to the lesson's theme

**Time management**:
- 1 min per pair (2 pairs = 2 min)
- 1 min for your synthesis

**Teacher tip**: If no volunteers, use the pairs you pre-selected. If a student rambles, gently redirect: *"So your main finding was [X]. Got it. Thank you."*

---

### MINUTE 0:39–0:42 — Share-Out: Risks & Benefits (3 min)

**What you do:**

1. Say:

> *"Now let's talk risks and benefits. Who wants to share one risk of using AI in healthcare? And one benefit?"*

2. Call on **2 students**. For each:
   - *"What's the risk you identified?"*
   - *"What's the benefit?"*

3. After each share, **push for depth**:
   - *"Can you give an example of how that risk might play out in a real hospital?"*
   - *"Why is that benefit important? Who does it help?"*

4. Write on the board under two columns:

| Risks | Benefits |
|:------|:---------|
| (Capture 2–3 student responses) | (Capture 2–3 student responses) |

5. **Synthesize** (30–45 seconds):

> *"Here's what I'm hearing: AI can help—faster triage, better access, catching things doctors might miss. But it also carries risks—misdiagnosis, bias, over-reliance. That's why we verify. Accuracy alone isn't enough. We also have to ask: Is it fair? Is it safe? Who does it help, and who might it harm?*
>
> *As future healthcare workers, your job is to use AI responsibly. That means: Ask → Verify → Refine. Every time."*

**What students do:**
- Share risks and benefits
- Listen to peers
- Internalize the balance: AI is powerful AND requires oversight

**Time management**:
- 1 min per student (2 students = 2 min)
- 1 min for your synthesis

**Teacher tip**: If students give very generic answers ("bias"), ask: *"What does that look like? Can you be more specific?"* If they give strong, specific answers, affirm: *"That's exactly the kind of critical thinking we need."*

---

### Common Student Responses & How to Respond

| Student Says | How to Respond |
|:-------------|:---------------|
| **Risk**: "The AI might be wrong" | "Yes. And what happens if it's wrong? Who gets harmed?" (Push for consequence) |
| **Risk**: "Bias" | "Good. Can you give an example? Like, trained on one population but used on another?" |
| **Benefit**: "It's faster" | "Faster at what? Triage? Diagnosis? And why does speed matter?" |
| **Benefit**: "Access in underserved areas" | "Exactly. If there's no radiologist available, AI can help—but still needs oversight." |
| "I'm not sure this is a good idea" | "That's a valid concern. What would need to be true for you to trust it? What safeguards?" |

---

### MINUTE 0:42–0:44 — Exit Ticket (2 min)

**What you do:**

1. Display **Slide 11** (Exit Ticket).

2. Say:

> *"Before you go, submit your exit ticket on Google Classroom. It's three short questions. This helps me know what you learned today. You have 2 minutes. Go."*

3. **Exit Ticket Question** (exact wording on Google Classroom):

---

> **Exit Ticket — Week 1**
>
> In 2–3 sentences, answer:
>
> 1. What is medical AI in plain language?
> 2. Name one place where AI is already used in healthcare (from today or your own knowledge).
> 3. Why is "Verify" especially important when using AI in medicine?
>
> Submit before you leave.

---

4. **Circulate** while students type:
   - Check that everyone is on Google Classroom
   - Help anyone who's stuck: *"Just answer in your own words. No need to be fancy."*

5. **Final 10 seconds**:
   - *"Finish up and hit submit. See you next class."*

**What students do:**
- Open Google Classroom
- Read the exit ticket questions
- Type 2–3 sentences for each
- Submit

**Teacher tip**: Don't extend past 2 minutes. If a few students need extra time, let them submit after class ends. The goal is a quick check, not a polished essay.

---

## KEY TEACHING POINTS (TO EMPHASIZE DURING DEBRIEF)

### 1. **Verification is non-negotiable in medicine**
- In other fields, a wrong answer might be inconvenient. In medicine, it can cause harm.
- That's why we check AI against trusted sources (CDC, NIH, research, clinical guidelines).

### 2. **AI is a tool, not a replacement**
- It supports clinical judgment—doesn't replace it.
- The doctor (or nurse, or you as a future healthcare worker) is still responsible.

### 3. **Accuracy ≠ Fairness**
- A system can be "accurate" overall and still fail certain populations.
- We have to ask: Who was in the training data? Does it work equally well for everyone?

### 4. **Ask → Verify → Refine is your workflow**
- Not just for AI—for any source of information.
- Clinical reasoning: gather data → form hypothesis → test against evidence → revise.

---

## ASSESSMENT (Formative)

### During Share-Out:

**Look for:**
- [ ] Can students articulate what they verified (and why)?
- [ ] Do students give specific risks and benefits (not just "bias" or "faster")?
- [ ] Are students connecting today's exercise to real clinical practice?

**Red flags** (note for next class):
- Student says "I trusted the AI" without checking
- Student can't name a single risk or benefit
- Student thinks AI will replace doctors

---

### Exit Ticket Rubric (Quick Scan):

**Question 1**: *What is medical AI in plain language?*

| Level | What to Look For |
|:------|:-----------------|
| **Strong** | "Finds patterns in patient data to help doctors make decisions" (or similar) |
| **Adequate** | "Uses data to predict diagnoses" or "Helps doctors" |
| **Needs support** | "A computer that treats patients" or no answer |

**Question 2**: *Name one place where AI is used in healthcare.*

| Level | What to Look For |
|:------|:-----------------|
| **Strong** | Specific example from today (ICU monitoring, radiology, pathology, drug discovery) |
| **Adequate** | Generic but accurate ("hospitals," "diagnosis") |
| **Needs support** | Incorrect or no answer |

**Question 3**: *Why is "Verify" important in medicine?*

| Level | What to Look For |
|:------|:-----------------|
| **Strong** | Mentions patient safety, harm, or evidence-based practice |
| **Adequate** | "To make sure it's right" |
| **Needs support** | No answer or unclear reasoning |

---

## WHAT TO DO WITH EXIT TICKET DATA

**Read exit tickets before the next class.** Use them to:

1. **Identify misconceptions**:
   - If multiple students say "AI replaces doctors" → address this explicitly next class
   - If students confuse "accuracy" with "fairness" → revisit this

2. **Celebrate strong responses**:
   - Next class: *"Someone wrote on the exit ticket: '[quote].' That's exactly right."*

3. **Adjust pacing**:
   - If most students nailed it → move forward
   - If many struggled → review key concepts briefly next class

---

## CLOSURE STATEMENT (Say This at 0:44)

> *"You did great work today. You asked questions, you verified answers, you thought critically about risks and benefits. That's what healthcare workers do—and that's what you'll keep doing all semester. See you next class."*

---

## TEACHER REFLECTION (After Class)

- Did students share thoughtful, specific insights during debrief? Or were they vague?
- Did the share-out feel rushed, or was there time for depth?
- Exit ticket scan: What % of students demonstrated understanding of medical AI and verification?
- What misconceptions emerged that I need to address next class?
- Did the overall flow (share-out → synthesis → exit ticket) feel smooth?

---

## APPENDIX: SAMPLE STRONG EXIT TICKET RESPONSES

Use these as examples for yourself (or share with students next class as a model).

---

**Student A:**

> 1. Medical AI finds patterns in patient data like vitals and lab results to help doctors predict outcomes or make diagnoses. It doesn't replace the doctor—it's a tool.
> 2. AI is used in ICU monitoring to predict if a patient might deteriorate, like with sepsis.
> 3. Verify is important because if the AI is wrong, patients could be harmed. Doctors need to check it against trusted sources and their own clinical judgment.

---

**Student B:**

> 1. AI in medicine analyzes data from past patients to make predictions for new patients.
> 2. Radiology—AI can flag possible findings on X-rays, but a radiologist still reviews them.
> 3. We need to verify because accuracy isn't the same as fairness. The AI might work better for some groups than others, and we have to check that.

---

**Student C:**

> 1. Medical AI looks for patterns in patient data to suggest diagnoses or predict risk.
> 2. Drug discovery—AI can screen thousands of compounds to find promising treatments.
> 3. In medicine, wrong information can cause harm. We verify against CDC, NIH, or research to make sure the AI's answer is safe and accurate.

---

*"First, do no harm. Verify, then act."*
